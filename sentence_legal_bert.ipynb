{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformer: Trained on Binary Citation Prediction\n",
    "\n",
    "- TODO Train on OCB+WS data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mostendorff/miniconda2/envs/legal-docsim/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers==0.4.1.2\r\n",
      "transformers==4.2.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze|grep transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from docsim.gold_standard import GoldStandard\n",
    "from smart_open import open\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from IPython.core.display import display\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from docsim.methods import RecSys\n",
    "from docsim.methods.keyed_vector_based import KeyedVectorRecSys, MultiKeyedVectorRecSys, EnsembleKeyedVectorRecSys\n",
    "from docsim.methods.text_based import TfIdfRecSys, Doc2VecRecSys, WeightedAvgWordVectorsRecSys\n",
    "from docsim.methods.transformer_based import TransformerRecSys\n",
    "from docsim.methods.graph_based import GraphEmbeddingRecSys\n",
    "from docsim.environment import get_env\n",
    "from docsim.experiment import Experiment\n",
    "from utils import get_mean_avg_precision, get_avg_precision, highlight_max\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Feb 10 19:28:47 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.31       Driver Version: 440.31       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  On   | 00000000:1B:00.0 Off |                  N/A |\r\n",
      "| 27%   32C    P8    12W / 250W |      0MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Quadro RTX 6000     On   | 00000000:1C:00.0 Off |                  Off |\r\n",
      "| 33%   28C    P8     4W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Quadro RTX 6000     On   | 00000000:1D:00.0 Off |                  Off |\r\n",
      "| 33%   33C    P8    34W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Quadro RTX 6000     On   | 00000000:1E:00.0 Off |                  Off |\r\n",
      "| 33%   31C    P8    15W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  GeForce RTX 208...  On   | 00000000:3D:00.0 Off |                  N/A |\r\n",
      "| 27%   28C    P8    20W / 250W |      0MiB / 11019MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  Quadro RTX 6000     On   | 00000000:3F:00.0 Off |                  Off |\r\n",
      "| 33%   28C    P8    17W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  Quadro RTX 6000     On   | 00000000:40:00.0 Off |                  Off |\r\n",
      "| 33%   32C    P8    30W / 260W |      0MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  Quadro RTX 6000     On   | 00000000:41:00.0 Off |                  Off |\r\n",
      "| 46%   69C    P2   259W / 260W |  23963MiB / 24220MiB |    100%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    7     29051      C   python                                     23951MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1,2,3,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.models import Pooling, Transformer\n",
    "from smart_open import open\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/datasets/BERT_pre_trained_models/pytorch/aueb-legal-bert-base-uncased'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch_size = 12\n",
    "\n",
    "data_dir = './data'\n",
    "\n",
    "experiment = 'ocb'\n",
    "experiment = 'wikisource'\n",
    "\n",
    "\n",
    "models_dir = '/data/datasets/BERT_pre_trained_models/pytorch'\n",
    "\n",
    "model_name = 'aueb-legal-bert-base-uncased'\n",
    "max_token_length = 512\n",
    "\n",
    "#model_name = 'legal-bert'\n",
    "#model_name = 'longformer-large-4096'\n",
    "#\n",
    "#model_name = 'longformer-base-4096'\n",
    "\n",
    "if 'longformer-large' in model_name:\n",
    "    train_batch_size = 4\n",
    "    max_token_length = 4096\n",
    "    \n",
    "if 'longformer-base' in model_name:\n",
    "    train_batch_size = 2\n",
    "    max_token_length = 3500 # 2048\n",
    "    \n",
    "\n",
    "train_epochs = 3\n",
    "\n",
    "#model_output_dir = f'./models/{experiment}/sentence_joint_{model_name}'\n",
    "model_output_dir = f'./models/{experiment}/sentence_{model_name}'\n",
    "\n",
    "\n",
    "model_name_or_path = os.path.join(models_dir, model_name)\n",
    "model_name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_token_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/wikisource/sentence_aueb-legal-bert-base-uncased'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Sentence transformer\n",
    "word_embedding_model = Transformer(model_name_or_path, max_seq_length=max_token_length)\n",
    "pooling_model = Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "#tokenizer = BertTokenizerFast.from_pretrained(model_name_or_path)\n",
    "tokenizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/experiments/mostendorff/legal-docsim/environments\n",
      "Environment detected: gpu_server2 (in default.yml)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from docsim.environment import get_env\n",
    "from docsim.experiment import Experiment\n",
    "from docsim.methods.graph_based import GraphEmbeddingRecSys\n",
    "from docsim.methods.text_based import TfIdfRecSys, Doc2VecRecSys, WeightedAvgWordVectorsRecSys\n",
    "from docsim.methods.transformer_based import TransformerRecSys, SentenceTransformerRecSys\n",
    "\n",
    "\n",
    "env = get_env()\n",
    "data_dir = Path(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on OCB+WS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Experiment: wikisource\n",
      "INFO:docsim.experiment:Documents after filtering: 1,378 (before 64,003)\n",
      "INFO:__main__:Citing docs - Not found: 0.9904856137895252; Found: 0.009514386210474875\n",
      "INFO:__main__:Negatives needed: 3154.0\n",
      "INFO:__main__:Experiment loaded\n",
      "INFO:__main__:Train on 6,308\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "\n",
    "pos_label = 1.\n",
    "neg_label = 0.\n",
    "\n",
    "\n",
    "# Sentence transformer data\n",
    "train_examples = []\n",
    "exps = [\n",
    "    #'ocb',\n",
    "    'wikisource'\n",
    "]\n",
    "\n",
    "for experiment in exps:    \n",
    "    logger.info(f'Experiment: {experiment}')\n",
    "    exp = Experiment(name=experiment, env=env, data_dir=data_dir)\n",
    "    exp.load_data()\n",
    "    exp.filter_docs()\n",
    "\n",
    "    # Extract positive samples based on citations\n",
    "    not_found = 0\n",
    "    found = 0\n",
    "    cit_ids = set()\n",
    "\n",
    "    pos_from_texts = []\n",
    "    pos_to_texts = []\n",
    "\n",
    "    for cit in exp.cits:\n",
    "        from_id, to_id = cit\n",
    "\n",
    "        if from_id in exp.doc_id2idx and to_id in exp.doc_id2idx:\n",
    "            cit_id = tuple(sorted([from_id, to_id]))\n",
    "            cit_ids.add(cit_id)\n",
    "\n",
    "            pos_from_texts.append(exp.texts[exp.doc_id2idx[from_id]])\n",
    "            pos_to_texts.append(exp.texts[exp.doc_id2idx[to_id]]) \n",
    "            found += 1\n",
    "        else:\n",
    "            not_found += 1\n",
    "\n",
    "    logger.info(f'Citing docs - Not found: {not_found / len(exp.cits)}; Found: {found / len(exp.cits)}')\n",
    "\n",
    "    # negative samples\n",
    "    neg_ratio = 1.0\n",
    "    neg_needed = len(pos_from_texts) * neg_ratio\n",
    "\n",
    "    logger.info(f'Negatives needed: {neg_needed}')\n",
    "\n",
    "    neg_from_texts = []\n",
    "    neg_to_texts = []\n",
    "\n",
    "    while len(neg_from_texts) < neg_needed:\n",
    "        # random samples\n",
    "        from_id = random.choice(exp.idx2doc_id)\n",
    "        to_id = random.choice(exp.idx2doc_id)\n",
    "\n",
    "        if from_id == to_id:\n",
    "            continue\n",
    "\n",
    "        cit_id = tuple(sorted([from_id, to_id]))\n",
    "\n",
    "        if cit_id in cit_ids:\n",
    "            continue\n",
    "\n",
    "        # add\n",
    "        cit_ids.add(cit_id)\n",
    "        neg_from_texts.append(exp.texts[exp.doc_id2idx[from_id]])\n",
    "        neg_to_texts.append(exp.texts[exp.doc_id2idx[to_id]])     \n",
    "    \n",
    "    # convert to st-input examples\n",
    "    for a, b in zip(pos_from_texts, pos_to_texts):\n",
    "        train_examples.append(\n",
    "            InputExample(texts=[a, b], label=pos_label)\n",
    "        )                \n",
    "\n",
    "    for a, b in zip(neg_from_texts, neg_to_texts):\n",
    "        train_examples.append(\n",
    "            InputExample(texts=[a, b], label=neg_label)\n",
    "        )\n",
    "    \n",
    "    logger.info(f'Experiment loaded')\n",
    "    \n",
    "logger.info(f'Train on {len(train_examples):,}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Experiment: ocb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/experiments/mostendorff/legal-docsim/environments\n",
      "Environment detected: gpu_server2 (in default.yml)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docsim.experiment:Documents loaded: 1,632\n",
      "INFO:docsim.experiment:Unique documents in gold standard: 1,623\n",
      "INFO:docsim.experiment:Documents after filtering: 1,590 (before 1,632)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from docsim.environment import get_env\n",
    "from docsim.experiment import Experiment\n",
    "from docsim.methods.graph_based import GraphEmbeddingRecSys\n",
    "from docsim.methods.text_based import TfIdfRecSys, Doc2VecRecSys, WeightedAvgWordVectorsRecSys\n",
    "from docsim.methods.transformer_based import TransformerRecSys, SentenceTransformerRecSys\n",
    "\n",
    "\n",
    "env = get_env()\n",
    "data_dir = Path(data_dir)\n",
    "\n",
    "logger.info(f'Experiment: {experiment}')\n",
    "\n",
    "exp = Experiment(name=experiment, env=env, data_dir=data_dir)\n",
    "\n",
    "exp.load_data()\n",
    "exp.filter_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1590"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = exp.texts\n",
    "cits = exp.cits\n",
    "doc_id2idx = exp.doc_id2idx\n",
    "idx2doc_id = exp.idx2doc_id\n",
    "\n",
    "len(exp.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70865"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp.cits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1994907', '197 N. Y. 541'],\n",
       " ['7797724', '960 F.2d 1217'],\n",
       " ['4334708', '315 U. S. 568']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.cits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "\n",
    "class CitedDocumentsDataset(Dataset):\n",
    "    pos_label = 1.\n",
    "    neg_label = 0.\n",
    "    \n",
    "    def __init__(self, exp, tokenizer, return_labels=True, sample_n=0, max_length=512):\n",
    "        \n",
    "        self.texts = exp.texts\n",
    "        self.cits = exp.cits\n",
    "        self.doc_id2idx = exp.doc_id2idx\n",
    "        self.idx2doc_id = exp.idx2doc_id\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.return_labels = return_labels\n",
    "        self.sample_n = sample_n\n",
    "        self.inputs = []\n",
    "        self.samples = []\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def load(self, tokenize=True):\n",
    "        logger.info(f'Corpus size: {len(self.doc_id2idx)}')\n",
    "\n",
    "        # Extract positive samples based on citations\n",
    "        not_found = 0\n",
    "        found = 0\n",
    "        cit_ids = set()\n",
    "\n",
    "        pos_from_texts = []\n",
    "        pos_to_texts = []\n",
    "\n",
    "        for cit in self.cits:\n",
    "\n",
    "            from_id, to_id = cit\n",
    "\n",
    "            if from_id in self.doc_id2idx and to_id in self.doc_id2idx:\n",
    "                cit_id = tuple(sorted([from_id, to_id]))\n",
    "                cit_ids.add(cit_id)\n",
    "\n",
    "                pos_from_texts.append(self.texts[self.doc_id2idx[from_id]])\n",
    "                pos_to_texts.append(self.texts[self.doc_id2idx[to_id]])        \n",
    "\n",
    "                found += 1\n",
    "            else:\n",
    "                #raise ValueError(cit)\n",
    "                not_found += 1\n",
    "\n",
    "        logger.info(f'Citing docs - Not found: {not_found / len(self.cits)}; Found: {found / len(self.cits)}')\n",
    "\n",
    "\n",
    "        # negative samples\n",
    "        neg_ratio = 1.0\n",
    "        neg_needed = len(pos_from_texts) * neg_ratio\n",
    "\n",
    "        logger.info(f'Negatives needed: {neg_needed}')\n",
    "\n",
    "        neg_from_texts = []\n",
    "        neg_to_texts = []\n",
    "\n",
    "        while len(neg_from_texts) < neg_needed:\n",
    "            # random samples\n",
    "            from_id = random.choice(self.idx2doc_id)\n",
    "            to_id = random.choice(self.idx2doc_id)\n",
    "\n",
    "            if from_id == to_id:\n",
    "                continue\n",
    "\n",
    "            cit_id = tuple(sorted([from_id, to_id]))\n",
    "\n",
    "            if cit_id in cit_ids:\n",
    "                continue\n",
    "\n",
    "            # add\n",
    "            cit_ids.add(cit_id)\n",
    "            neg_from_texts.append(self.texts[self.doc_id2idx[from_id]])\n",
    "            neg_to_texts.append(self.texts[self.doc_id2idx[to_id]])     \n",
    "\n",
    "        if tokenize:            \n",
    "            logger.info(f'Tokenize... {len(pos_from_texts):,} + {len(neg_from_texts):,}  from texts')\n",
    "\n",
    "            self.from_inputs = self.tokenizer(\n",
    "                text=pos_from_texts + neg_from_texts,\n",
    "                add_special_tokens=False,\n",
    "                return_attention_mask=False,\n",
    "                return_tensors='pt',\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                truncation=True,\n",
    "                return_token_type_ids=False,\n",
    "            )\n",
    "\n",
    "            logger.info(f'Tokenize... {len(pos_to_texts):,} + {len(neg_to_texts):,} to texts')\n",
    "\n",
    "            self.to_inputs = self.tokenizer(\n",
    "                text=pos_to_texts + neg_to_texts,\n",
    "                add_special_tokens=False,\n",
    "                return_attention_mask=False,\n",
    "                return_tensors='pt',\n",
    "                padding='max_length',\n",
    "                max_length=self.max_length,\n",
    "                truncation=True,\n",
    "                return_token_type_ids=False,\n",
    "            )\n",
    "\n",
    "            if self.return_labels:\n",
    "                labels = [self.pos_label] * len(pos_from_texts) + [self.neg_label] * len(neg_from_texts) \n",
    "\n",
    "                self.labels = torch.tensor(labels)\n",
    "\n",
    "            logger.info('Dataset loaded')\n",
    "            \n",
    "            return self.from_inputs, self.to_inputs, self.labels\n",
    "            \n",
    "        else:\n",
    "            # return input examples -> sentence transformer inputs\n",
    "            input_examples = []\n",
    "            \n",
    "            for a, b in zip(pos_from_texts, pos_to_texts):\n",
    "                input_examples.append(\n",
    "                    InputExample(texts=[a, b], label=self.pos_label)\n",
    "                )                \n",
    "            \n",
    "            for a, b in zip(neg_from_texts, neg_to_texts):\n",
    "                input_examples.append(\n",
    "                    InputExample(texts=[a, b], label=self.neg_label)\n",
    "                )\n",
    "                \n",
    "            return input_examples\n",
    "            \n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        return [\n",
    "            self.from_inputs['input_ids'][idx], \n",
    "            self.to_inputs['input_ids'][idx]\n",
    "        ], self.labels[idx]\n",
    "        #return {k: v[idx] for k, v in self.inputs.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.from_inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CitedDocumentsDataset(exp, tokenizer, max_length=max_token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_ds.load(tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Corpus size: 1590\n",
      "INFO:__main__:Citing docs - Not found: 0.9772525224017498; Found: 0.022747477598250194\n",
      "INFO:__main__:Negatives needed: 1612.0\n"
     ]
    }
   ],
   "source": [
    "train_examples = train_ds.load(tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_examples, shuffle=True, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.CosineSimilarityLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37860</th>\n",
       "      <td>86931</td>\n",
       "      <td>93489</td>\n",
       "      <td>United States Supreme Court decisions on treaties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173518</th>\n",
       "      <td>86725</td>\n",
       "      <td>85334</td>\n",
       "      <td>United States Supreme Court decisions on evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>99561</td>\n",
       "      <td>85214</td>\n",
       "      <td>United States Supreme Court decisions on treaties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156242</th>\n",
       "      <td>96786</td>\n",
       "      <td>101911</td>\n",
       "      <td>United States Supreme Court decisions on the F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187363</th>\n",
       "      <td>112513</td>\n",
       "      <td>112464</td>\n",
       "      <td>United States Supreme Court decisions on the F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117259</th>\n",
       "      <td>90228</td>\n",
       "      <td>89526</td>\n",
       "      <td>United States Supreme Court decisions on secur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12898</th>\n",
       "      <td>89181</td>\n",
       "      <td>89949</td>\n",
       "      <td>United States Supreme Court decisions on treaties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44444</th>\n",
       "      <td>88305</td>\n",
       "      <td>97934</td>\n",
       "      <td>United States Supreme Court decisions on treaties</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182609</th>\n",
       "      <td>88112</td>\n",
       "      <td>88493</td>\n",
       "      <td>United States Supreme Court decisions on civil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6162</th>\n",
       "      <td>96406</td>\n",
       "      <td>88421</td>\n",
       "      <td>United States Supreme Court decisions on treaties</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       seed_id target_id                                              label\n",
       "37860    86931     93489  United States Supreme Court decisions on treaties\n",
       "173518   86725     85334  United States Supreme Court decisions on evidence\n",
       "6851     99561     85214  United States Supreme Court decisions on treaties\n",
       "156242   96786    101911  United States Supreme Court decisions on the F...\n",
       "187363  112513    112464  United States Supreme Court decisions on the F...\n",
       "...        ...       ...                                                ...\n",
       "117259   90228     89526  United States Supreme Court decisions on secur...\n",
       "12898    89181     89949  United States Supreme Court decisions on treaties\n",
       "44444    88305     97934  United States Supreme Court decisions on treaties\n",
       "182609   88112     88493  United States Supreme Court decisions on civil...\n",
       "6162     96406     88421  United States Supreme Court decisions on treaties\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of gold standard\n",
    "gs_df = exp.gs.df.sample(n=100)\n",
    "gs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation.BinaryClassificationEvaluator import BinaryClassificationEvaluator\n",
    "\n",
    "# Evaluator\n",
    "\n",
    "from_texts = []\n",
    "to_texts = []\n",
    "\n",
    "for from_id, to_id in gs_df[['seed_id', 'target_id']].values:\n",
    "    if from_id in exp.doc_id2idx and to_id in exp.doc_id2idx:\n",
    "        from_texts.append(exp.texts[exp.doc_id2idx[from_id]])\n",
    "        to_texts.append(exp.texts[exp.doc_id2idx[to_id]])\n",
    "        \n",
    "labels = [1] * len(from_texts)\n",
    "\n",
    "test_limit = 10\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(from_texts[:test_limit], to_texts[:test_limit], labels[:test_limit])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1fef145e3649c9a059cd56ad7f2c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ab0208835647039282037b31742d7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=526.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4919047ad222444a9cc3f7c15436d102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=526.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b7050482cd46a4bbc9e95473dd6a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=526.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(\n",
    "    train_objectives=[(train_dl, train_loss)],\n",
    "    epochs=train_epochs, # try 1-4\n",
    "    warmup_steps=100,\n",
    "    #evaluator=evaluator,\n",
    "    #evaluation_steps=evaluation_steps,  # increase to 5000 (full dataset => 20k steps)\n",
    "    output_path=model_output_dir,\n",
    "    #output_path_ignore_not_empty=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Save model to ./models/wikisource/sentence_aueb-legal-bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "model.save(model_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/wikisource/sentence_aueb-legal-bert-base-uncased'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:legal-docsim]",
   "language": "python",
   "name": "conda-env-legal-docsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
